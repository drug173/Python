{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2134d88f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.datasets as dsets\n",
    "import torchvision.transforms as transforms\n",
    "from torch.autograd import Variable\n",
    "import os\n",
    "\n",
    "#os.environ['CUDA_VISIBLE_DEVICES'] = '0'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d55dd368",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1., 2.], device='cuda:0')\n",
      "0\n",
      "tensor([1., 2.], device='cuda:0')\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'NVIDIA GeForce RTX 3060'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cuda0 = torch.device('cuda:0')\n",
    "x = torch.tensor([1., 2.], device=cuda0)\n",
    "print(x)\n",
    "\n",
    "tt=torch.cuda.current_device()\n",
    "print(tt)\n",
    "torch.cuda.device_count()\n",
    "\n",
    "b = torch.tensor([1., 2.]).cuda()\n",
    "print(b)\n",
    "\n",
    "torch.cuda.get_device_name()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3c2569b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#c = torch.tensor([1., 2.])\n",
    "#print(c)\n",
    "#cc = c.to(cuda0)\n",
    "#print(cc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "40537d51",
   "metadata": {},
   "outputs": [],
   "source": [
    "#torch.cuda.get_device_properties(0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "59565364",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_size = 784       # Размеры изображения = 28 x 28 = 784\n",
    "hidden_size = 500      # Количество узлов на скрытом слое\n",
    "num_classes = 10       # Число классов на выходе. В этом случае от 0 до 9\n",
    "num_epochs = 5         # Количество тренировок всего набора данных\n",
    "batch_size = 100       # Размер входных данных для одной итерации\n",
    "learning_rate = 0.001  # Скорость конвергенции\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c7a78551",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = dsets.MNIST(\n",
    "    root='./MNIST',\n",
    "    train=True,\n",
    "    transform=transforms.ToTensor(),\n",
    "    download=True\n",
    ")\n",
    " \n",
    "test_dataset = dsets.MNIST(\n",
    "    root='./MNIST',\n",
    "    train=False,\n",
    "    transform=transforms.ToTensor()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e8601aff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torchvision.datasets.mnist.MNIST'>\n"
     ]
    }
   ],
   "source": [
    "print(type(train_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "229fc583",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e2d85e30",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = torch.utils.data.DataLoader(\n",
    "    dataset=train_dataset,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True\n",
    ")\n",
    " \n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "    dataset=test_dataset,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "60575e35",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_classes):\n",
    "        super(Net, self).__init__()                    # Наследуемый родительским классом nn.Module\n",
    "        self.fc1 = nn.Linear(input_size, hidden_size)  # 1й связанный слой: 784 (данные входа) -> 500 (скрытый узел)\n",
    "        self.relu = nn.ReLU()                          # Нелинейный слой ReLU max(0,x)\n",
    "        self.fc2 = nn.Linear(hidden_size, num_classes) # 2й связанный слой: 500 (скрытый узел) -> 10 (класс вывода)\n",
    "    \n",
    "    def forward(self, x):                              # Передний пропуск: складывание каждого слоя вместе\n",
    "        out = self.fc1(x)\n",
    "        out = self.relu(out)\n",
    "        out = self.fc2(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "849dfcfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "net = Net(input_size, hidden_size, num_classes)\n",
    "device = torch.device(cuda0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4d9bd931",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Net(\n",
       "  (fc1): Linear(in_features=784, out_features=500, bias=True)\n",
       "  (relu): ReLU()\n",
       "  (fc2): Linear(in_features=500, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net.cuda() # Включаем GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "360a13c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OrderedDict([('fc1.weight', tensor([[-1.7886e-02,  2.4059e-02,  1.2127e-02,  ...,  8.2212e-03,\n",
      "         -1.6209e-02, -2.3337e-02],\n",
      "        [-3.1160e-02, -2.8851e-02, -2.9725e-02,  ...,  8.0366e-05,\n",
      "          2.5447e-02,  1.7749e-02],\n",
      "        [ 2.4921e-02, -1.5488e-02, -1.4563e-02,  ..., -3.3916e-02,\n",
      "         -3.5218e-02,  4.6975e-03],\n",
      "        ...,\n",
      "        [-6.3645e-04,  1.0396e-02, -1.9093e-02,  ...,  2.0065e-02,\n",
      "          8.5642e-03,  2.7956e-02],\n",
      "        [-3.0655e-02,  2.6850e-02, -2.5427e-02,  ..., -1.5808e-02,\n",
      "          3.0509e-02, -2.7482e-02],\n",
      "        [ 2.1631e-03, -5.4711e-03, -3.0814e-02,  ...,  3.2413e-02,\n",
      "          1.8580e-02, -1.5256e-02]], device='cuda:0')), ('fc1.bias', tensor([ 2.6183e-02,  3.0136e-02, -2.7451e-02, -2.9345e-02, -6.3442e-03,\n",
      "        -1.4809e-02, -3.3506e-02,  3.3064e-02, -9.8210e-03, -1.1015e-02,\n",
      "         3.2388e-02,  2.4688e-02,  6.9772e-03,  1.4238e-03, -6.5163e-03,\n",
      "         3.5321e-02,  2.9798e-02,  2.1694e-02,  1.8111e-02, -2.9808e-02,\n",
      "         4.7781e-03,  1.4255e-02,  5.6983e-03,  2.6304e-02,  8.1516e-03,\n",
      "        -1.3236e-02, -7.9953e-03,  7.9863e-03,  2.5619e-02, -1.7884e-02,\n",
      "         2.9199e-02, -7.8184e-03, -2.2751e-02,  1.0371e-03,  3.1684e-02,\n",
      "         1.1755e-02, -2.6364e-02, -2.5964e-02, -9.1340e-03, -1.0951e-02,\n",
      "        -2.0142e-02,  2.6574e-02, -5.3098e-03, -3.1305e-02, -1.3207e-02,\n",
      "         2.3302e-02, -4.5704e-03,  1.1447e-02,  1.4612e-02, -2.8320e-02,\n",
      "        -2.6768e-02,  2.0118e-02, -1.0996e-02,  3.3572e-02, -7.6204e-03,\n",
      "        -2.9695e-02, -5.7020e-03,  2.6887e-03,  7.0050e-03,  1.4131e-02,\n",
      "        -2.2412e-02,  5.0001e-03, -2.3169e-02, -1.5850e-02, -5.1132e-03,\n",
      "        -1.3796e-02, -2.9799e-03, -2.8807e-02,  1.1889e-02,  1.8431e-02,\n",
      "        -2.1413e-02,  3.7022e-03, -2.7451e-02, -1.7652e-02, -2.2840e-02,\n",
      "        -1.5373e-02,  2.0879e-02,  3.0065e-02,  1.8595e-03, -6.2721e-03,\n",
      "         1.9359e-02, -2.5061e-02,  1.3465e-02,  2.1514e-02,  1.3779e-02,\n",
      "         8.4560e-03,  8.2109e-03,  1.3568e-02,  2.4904e-02,  5.5649e-03,\n",
      "         2.9861e-02, -1.6393e-02, -7.0588e-03,  1.8388e-02,  8.5237e-03,\n",
      "        -3.1603e-02,  1.0249e-02,  3.2049e-02, -9.3875e-03,  3.1896e-02,\n",
      "         2.3987e-02, -2.7060e-02, -1.5691e-02,  1.8692e-02,  3.3300e-02,\n",
      "        -8.7413e-03, -1.9810e-02, -1.8603e-03, -2.3024e-02, -4.2580e-04,\n",
      "        -2.9074e-02,  2.0633e-02,  3.2852e-02, -1.3536e-02, -2.4202e-02,\n",
      "         8.9072e-03,  8.8598e-04,  2.8290e-02, -3.1451e-02,  3.2730e-02,\n",
      "         2.0860e-02,  2.2014e-02, -3.3781e-02, -1.0548e-02, -1.5773e-02,\n",
      "         3.0323e-02,  2.1605e-02,  1.1326e-02, -4.3889e-03, -1.2380e-02,\n",
      "         8.0199e-03,  1.3964e-02,  3.3310e-02, -2.8248e-02, -5.7102e-03,\n",
      "         3.4748e-02,  3.8820e-03,  2.8089e-02, -1.4341e-02, -1.3710e-02,\n",
      "         9.6792e-03,  2.7366e-02, -2.8302e-02,  2.0664e-02, -2.3733e-03,\n",
      "        -1.0131e-02,  1.2914e-02, -2.4893e-02,  2.5706e-03,  1.6134e-02,\n",
      "         1.4369e-02, -2.2036e-02,  1.9871e-02,  3.4285e-02,  3.5137e-02,\n",
      "         2.9833e-02,  3.0973e-04,  4.3934e-03, -2.4525e-02, -2.3744e-02,\n",
      "         1.9467e-02,  2.9024e-02, -5.8918e-03,  4.4204e-03,  2.7561e-02,\n",
      "         2.7948e-03,  9.9964e-03, -4.5829e-03,  3.4596e-02,  2.2704e-02,\n",
      "         3.9941e-03,  2.0536e-02, -2.6720e-02, -1.0413e-02, -1.4981e-02,\n",
      "        -1.9341e-02, -1.3495e-02, -2.9124e-03,  9.6642e-03, -3.3878e-02,\n",
      "        -2.7915e-02,  2.7806e-02,  2.8259e-03,  1.1875e-02,  2.7523e-02,\n",
      "        -8.5093e-03, -2.0991e-02, -4.8029e-03, -1.4456e-02, -1.0776e-02,\n",
      "         5.7383e-03,  2.4696e-02, -3.4661e-02, -1.5461e-04, -3.4959e-02,\n",
      "        -2.0899e-02,  9.3075e-03, -2.2905e-02,  1.5253e-03, -1.8647e-02,\n",
      "        -1.0972e-02, -3.3529e-02,  2.1080e-02, -1.2306e-02, -2.9918e-02,\n",
      "        -3.3364e-02, -2.4054e-02, -1.1883e-02,  1.1671e-02, -2.8621e-02,\n",
      "         3.3031e-02,  2.5341e-02,  1.4114e-02,  2.1216e-02,  2.9583e-02,\n",
      "        -1.7171e-02,  8.6181e-03,  1.4062e-02,  2.2883e-02,  2.5337e-02,\n",
      "        -9.4401e-03,  2.1037e-02,  4.3657e-03, -3.0443e-02,  1.2096e-02,\n",
      "        -9.1624e-03, -1.4826e-02,  2.9118e-02, -4.4093e-04, -2.6056e-02,\n",
      "         3.3053e-02,  2.7640e-02,  1.6028e-02, -6.0892e-03,  1.0224e-02,\n",
      "        -1.7400e-02, -1.8082e-02, -2.5254e-02,  9.4315e-03,  6.4901e-04,\n",
      "         2.9588e-02, -2.1866e-02, -8.9970e-03,  1.7639e-02, -2.2477e-02,\n",
      "        -2.0825e-02,  3.5075e-02, -1.2168e-02,  2.9596e-02, -1.6547e-02,\n",
      "        -1.7132e-02,  1.9416e-02, -3.0627e-02,  2.0706e-02,  2.8759e-02,\n",
      "        -2.5451e-02, -1.6941e-02, -3.1587e-02, -1.9427e-03, -9.2298e-03,\n",
      "        -2.4749e-02, -2.9783e-02,  1.7744e-03,  2.8234e-03,  1.1755e-02,\n",
      "        -2.6620e-02,  3.3280e-02, -2.0389e-02,  2.8445e-02, -2.3040e-02,\n",
      "         1.1759e-02,  1.1086e-02, -2.9332e-02,  1.9962e-02, -3.1328e-02,\n",
      "         6.5044e-03,  2.8419e-02,  1.1760e-02, -8.6299e-03, -1.1283e-02,\n",
      "         5.6186e-03,  2.2306e-02, -1.6591e-02,  2.1204e-02, -2.2919e-02,\n",
      "         3.0736e-02, -9.1483e-03, -2.1907e-02,  2.7233e-02,  3.4625e-02,\n",
      "        -3.0741e-02,  3.4494e-02,  9.1935e-03, -2.9749e-02,  8.5055e-03,\n",
      "        -3.1465e-02,  8.4952e-03, -3.6028e-03, -9.6763e-03, -2.7035e-02,\n",
      "        -2.2792e-02, -1.5458e-02,  3.2667e-02,  2.0527e-02, -1.5402e-02,\n",
      "        -1.9316e-02, -7.2291e-03,  1.6251e-02, -2.3132e-02,  2.7946e-02,\n",
      "        -3.3917e-03,  1.1357e-02, -3.1417e-02,  1.8177e-02,  3.4812e-02,\n",
      "         4.9893e-03, -2.8757e-02,  2.3570e-02,  1.1399e-03,  1.0101e-02,\n",
      "        -2.8329e-02,  1.9918e-02, -2.7083e-02, -1.3861e-02,  1.9301e-02,\n",
      "        -2.2208e-02, -1.6242e-02, -3.5263e-02, -2.7822e-02,  7.0434e-03,\n",
      "        -2.2086e-02, -4.9839e-03, -2.1013e-02,  9.8250e-03,  1.2587e-02,\n",
      "        -1.6486e-02, -9.6724e-03,  1.7123e-02, -9.2466e-03, -1.5052e-02,\n",
      "         3.3083e-03,  2.4440e-02,  2.1002e-02, -1.3674e-04,  1.4374e-02,\n",
      "         1.4258e-02, -7.5389e-03,  9.0228e-03,  2.7803e-02,  3.4985e-02,\n",
      "        -1.1070e-02,  2.3956e-02,  2.7627e-02, -3.1907e-02,  1.1421e-02,\n",
      "         2.2116e-03, -3.5124e-02,  4.1484e-03, -1.9182e-02, -1.3544e-02,\n",
      "        -2.8097e-02, -1.6187e-02, -1.8205e-02, -9.1290e-03,  4.7545e-03,\n",
      "         1.9010e-02, -1.8198e-02,  2.6809e-02, -6.1229e-03,  2.0799e-02,\n",
      "         2.8375e-02,  1.1358e-02, -2.0450e-02,  9.1226e-03, -1.8799e-02,\n",
      "        -1.6699e-02, -3.0045e-02,  2.4044e-02,  3.0843e-02,  1.4589e-02,\n",
      "        -2.1428e-02, -8.8823e-03,  1.0107e-03,  2.0851e-02,  3.0344e-02,\n",
      "        -2.6180e-02, -1.4181e-02, -3.3486e-02,  2.3671e-02,  2.3271e-02,\n",
      "         3.5122e-02,  2.4764e-02,  2.2374e-02, -2.8484e-02,  9.2832e-03,\n",
      "        -7.4414e-04, -3.2158e-02, -1.3600e-02,  2.9924e-03, -2.0905e-02,\n",
      "        -1.0018e-02,  2.6954e-02,  3.2473e-02, -2.0369e-02,  5.1022e-03,\n",
      "        -2.6628e-02, -9.2734e-03, -2.1249e-02,  2.4839e-02,  3.3202e-02,\n",
      "         1.9674e-02,  1.3963e-03,  1.7938e-02, -9.0407e-03, -3.2450e-02,\n",
      "        -5.4315e-04,  2.3589e-02, -2.4338e-02, -1.0152e-02,  2.5789e-02,\n",
      "        -1.1873e-02,  3.5694e-02,  2.1394e-02, -3.5451e-02,  2.0245e-02,\n",
      "         9.9324e-03,  2.6284e-02,  1.7922e-02,  2.5162e-02, -3.0163e-02,\n",
      "         1.4810e-03,  1.6367e-02,  5.3082e-03,  2.4016e-02, -2.8772e-02,\n",
      "        -2.6711e-02,  2.3916e-02, -1.6951e-02, -1.3849e-03, -3.3518e-02,\n",
      "        -1.5069e-02, -1.9484e-02,  7.5200e-03, -1.6622e-02,  4.4036e-03,\n",
      "        -3.3287e-02, -1.9125e-02, -3.4813e-02, -6.5391e-03,  2.8559e-02,\n",
      "         1.1562e-02, -3.5205e-02, -2.3186e-02, -2.1757e-02,  1.3257e-02,\n",
      "        -3.2399e-02, -2.5373e-02, -4.2908e-05,  1.6792e-02, -2.1323e-02,\n",
      "         6.2240e-03, -1.9133e-02,  1.8690e-02,  2.2421e-03,  2.6128e-02,\n",
      "        -3.3165e-02, -1.4247e-02, -1.2394e-02,  9.9463e-03,  1.5797e-02,\n",
      "        -2.6913e-02,  2.2541e-02,  1.3031e-02, -2.3399e-02,  1.2717e-02,\n",
      "        -2.2860e-02, -1.3188e-02,  6.7287e-03,  5.2115e-03, -3.4769e-02,\n",
      "        -2.2626e-02, -2.1061e-02, -1.1467e-02, -1.8151e-02,  3.4117e-02,\n",
      "         1.2087e-02, -2.7287e-02,  3.1188e-02, -1.6583e-04, -2.6832e-02,\n",
      "        -3.7569e-03,  2.0989e-02, -1.3227e-02, -2.4252e-02,  2.9429e-02,\n",
      "         3.4921e-03,  2.6516e-03, -2.8811e-02,  3.1651e-02, -8.2522e-03],\n",
      "       device='cuda:0')), ('fc2.weight', tensor([[-4.2013e-02, -2.2446e-02,  2.6213e-02,  ...,  1.2616e-02,\n",
      "          1.6402e-02,  3.0687e-02],\n",
      "        [ 1.7097e-02, -1.0145e-02, -3.4635e-02,  ..., -3.5596e-02,\n",
      "          2.9260e-02,  2.6306e-02],\n",
      "        [ 1.0751e-02,  1.0807e-02,  2.2446e-02,  ..., -5.9171e-03,\n",
      "          1.0032e-02, -3.2368e-02],\n",
      "        ...,\n",
      "        [ 1.5815e-03, -1.6098e-02,  3.2984e-02,  ...,  3.4843e-02,\n",
      "         -3.2772e-02, -1.8184e-02],\n",
      "        [-3.9300e-02, -3.7136e-02, -3.3008e-02,  ..., -1.3172e-02,\n",
      "          5.4089e-03,  2.7983e-02],\n",
      "        [ 2.7459e-02, -3.6298e-02,  4.0545e-02,  ..., -9.2700e-05,\n",
      "         -3.8085e-03,  3.3357e-02]], device='cuda:0')), ('fc2.bias', tensor([ 0.0016,  0.0118,  0.0126,  0.0296,  0.0140, -0.0395, -0.0112,  0.0350,\n",
      "        -0.0004, -0.0096], device='cuda:0'))])\n"
     ]
    }
   ],
   "source": [
    "print(net.state_dict())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7b1e561c",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()   # Функция потерь\n",
    "optimizer = torch.optim.Adam(net.parameters(), lr=learning_rate)   # Оптимизатор градиентного спуска"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "dc4bdb49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/5], Step [100/600], Loss: 0.4704\n",
      "Epoch [1/5], Step [200/600], Loss: 0.4836\n",
      "Epoch [1/5], Step [300/600], Loss: 0.2666\n",
      "Epoch [1/5], Step [400/600], Loss: 0.2918\n",
      "Epoch [1/5], Step [500/600], Loss: 0.1363\n",
      "Epoch [1/5], Step [600/600], Loss: 0.0959\n",
      "Epoch [2/5], Step [100/600], Loss: 0.2181\n",
      "Epoch [2/5], Step [200/600], Loss: 0.1358\n",
      "Epoch [2/5], Step [300/600], Loss: 0.0681\n",
      "Epoch [2/5], Step [400/600], Loss: 0.0967\n",
      "Epoch [2/5], Step [500/600], Loss: 0.1020\n",
      "Epoch [2/5], Step [600/600], Loss: 0.1054\n",
      "Epoch [3/5], Step [100/600], Loss: 0.0979\n",
      "Epoch [3/5], Step [200/600], Loss: 0.1545\n",
      "Epoch [3/5], Step [300/600], Loss: 0.0497\n",
      "Epoch [3/5], Step [400/600], Loss: 0.1606\n",
      "Epoch [3/5], Step [500/600], Loss: 0.0590\n",
      "Epoch [3/5], Step [600/600], Loss: 0.0386\n",
      "Epoch [4/5], Step [100/600], Loss: 0.0338\n",
      "Epoch [4/5], Step [200/600], Loss: 0.0306\n",
      "Epoch [4/5], Step [300/600], Loss: 0.0580\n",
      "Epoch [4/5], Step [400/600], Loss: 0.0351\n",
      "Epoch [4/5], Step [500/600], Loss: 0.0308\n",
      "Epoch [4/5], Step [600/600], Loss: 0.0438\n",
      "Epoch [5/5], Step [100/600], Loss: 0.0186\n",
      "Epoch [5/5], Step [200/600], Loss: 0.0568\n",
      "Epoch [5/5], Step [300/600], Loss: 0.0121\n",
      "Epoch [5/5], Step [400/600], Loss: 0.0591\n",
      "Epoch [5/5], Step [500/600], Loss: 0.0414\n",
      "Epoch [5/5], Step [600/600], Loss: 0.0286\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(num_epochs):\n",
    "    for i, (images, labels) in enumerate(train_loader):   # Загрузка партии изображений с индексом, данными, классом\n",
    "             \n",
    "        images = Variable(images.view(-1, 28*28)).to(cuda0)         # Конвертация тензора в переменную: изменяем изображение с вектора, размером 784 на матрицу 28 x 28\n",
    "        labels = Variable(labels).to(cuda0)\n",
    "        \n",
    "        optimizer.zero_grad()                             # Инициализация скрытых масс до нулей\n",
    "        outputs = net(images)     # Передний пропуск: определение выходного класса, данного изображения\n",
    "            \n",
    "        loss = criterion(outputs, labels)                # Определение потерь: разница между выходным классом и предварительно заданной меткой\n",
    "        loss.backward()                                   # Обратный проход: определение параметра weight\n",
    "        optimizer.step()                                  # Оптимизатор: обновление параметров веса в скрытых узлах\n",
    "        \n",
    "        if (i+1) % 100 == 0:                              # Логирование\n",
    "            print('Epoch [%d/%d], Step [%d/%d], Loss: %.4f'\n",
    "                 %(epoch+1, num_epochs, i+1, len(train_dataset)//batch_size, loss.data.item()))\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5ff67079",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(net.state_dict(), 'fnn_model.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "cedb301b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net(\n",
      "  (fc1): Linear(in_features=784, out_features=500, bias=True)\n",
      "  (relu): ReLU()\n",
      "  (fc2): Linear(in_features=500, out_features=10, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "print(net) # Структура сети"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2dc5f649",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "name:  fc1.weight\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:  torch.Size([500, 784])\n",
      "param.requires_grad:  True\n",
      "=====\n",
      "name:  fc1.bias\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:  torch.Size([500])\n",
      "param.requires_grad:  True\n",
      "=====\n",
      "name:  fc2.weight\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:  torch.Size([10, 500])\n",
      "param.requires_grad:  True\n",
      "=====\n",
      "name:  fc2.bias\n",
      "<class 'torch.nn.parameter.Parameter'>\n",
      "param.shape:  torch.Size([10])\n",
      "param.requires_grad:  True\n",
      "=====\n"
     ]
    }
   ],
   "source": [
    "# Просмотр параметров (веса и смещения)\n",
    "\n",
    "for name, param in net.named_parameters():\n",
    "    print('name: ', name)\n",
    "    print(type(param))\n",
    "    print('param.shape: ', param.shape)\n",
    "    print('param.requires_grad: ', param.requires_grad)\n",
    "    print('=====')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4537691c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fc1.weight : False\n",
      "fc1.bias : False\n",
      "fc2.weight : True\n",
      "fc2.bias : True\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for name, param in net.named_parameters():\n",
    "    if name in ['fc2.weight', 'fc2.bias']:\n",
    "        param.requires_grad = True\n",
    "    else:\n",
    "        param.requires_grad = False\n",
    "\n",
    "for name, param in net.named_parameters():\n",
    "    print(name, ':', param.requires_grad)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "89e6ee4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#сохраняем веса\n",
    "\n",
    "torch.save (net.state_dict(), \"weights_path_name.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9de489c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# сохраняем всю модель\n",
    "\n",
    "torch.save (net.state_dict(), \"model.pth\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "adbb9222",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OrderedDict([('fc1.weight', tensor([[-1.7886e-02,  2.4059e-02,  1.2127e-02,  ...,  8.2212e-03,\n",
      "         -1.6209e-02, -2.3337e-02],\n",
      "        [-3.1160e-02, -2.8851e-02, -2.9725e-02,  ...,  8.0366e-05,\n",
      "          2.5447e-02,  1.7749e-02],\n",
      "        [ 2.4921e-02, -1.5488e-02, -1.4563e-02,  ..., -3.3916e-02,\n",
      "         -3.5218e-02,  4.6975e-03],\n",
      "        ...,\n",
      "        [-6.3645e-04,  1.0396e-02, -1.9093e-02,  ...,  2.0065e-02,\n",
      "          8.5642e-03,  2.7956e-02],\n",
      "        [-3.0655e-02,  2.6850e-02, -2.5427e-02,  ..., -1.5808e-02,\n",
      "          3.0509e-02, -2.7482e-02],\n",
      "        [ 2.1631e-03, -5.4711e-03, -3.0814e-02,  ...,  3.2413e-02,\n",
      "          1.8580e-02, -1.5256e-02]], device='cuda:0')), ('fc1.bias', tensor([ 8.2043e-02,  6.0930e-02,  9.9372e-03, -5.6765e-02,  6.8273e-02,\n",
      "         1.3366e-02, -2.4556e-02,  5.1160e-02, -5.6142e-02, -1.2249e-02,\n",
      "        -5.8979e-03,  8.6617e-02,  1.0421e-01,  3.0909e-02,  4.6933e-02,\n",
      "         8.8124e-02,  7.6432e-02,  7.6576e-02,  6.7188e-02, -2.8336e-02,\n",
      "         3.3370e-02,  4.2127e-02,  1.3977e-02,  6.0468e-02, -2.8506e-02,\n",
      "         1.2651e-02, -2.5851e-02,  2.6722e-03,  2.8102e-02,  4.8534e-02,\n",
      "         4.2012e-02, -1.7587e-02, -6.2868e-02,  6.2016e-03,  2.3811e-02,\n",
      "         3.5235e-03,  2.5781e-02, -4.9496e-02,  8.3044e-02, -5.2250e-02,\n",
      "         6.7084e-02,  5.5141e-02, -3.8233e-03,  5.3941e-03, -8.2093e-02,\n",
      "         9.2013e-03,  6.0008e-02, -2.7361e-02, -1.0967e-02, -4.4540e-02,\n",
      "         1.2168e-02,  7.8466e-02,  2.6082e-02,  9.3506e-02, -1.5546e-02,\n",
      "         4.1067e-02,  8.4301e-02,  2.5206e-02, -1.3205e-02,  8.6457e-02,\n",
      "        -5.1045e-02, -4.5894e-02, -3.3125e-02, -2.1578e-02, -5.8781e-02,\n",
      "         2.1927e-02, -1.4323e-03,  4.9962e-03,  7.3865e-02,  9.4899e-02,\n",
      "         1.6358e-03,  5.6170e-02, -2.8200e-02,  1.5968e-02,  4.4554e-03,\n",
      "         7.4022e-03,  8.8637e-02,  1.2894e-02,  1.5637e-02, -2.1769e-02,\n",
      "         1.2947e-01,  3.7702e-02,  2.0709e-02,  1.3521e-02, -1.6583e-02,\n",
      "         3.3720e-02,  5.8617e-02, -2.2176e-02,  4.1782e-02, -3.5520e-02,\n",
      "         6.2981e-02, -4.1753e-02, -3.7944e-02,  5.1085e-02, -4.1796e-02,\n",
      "        -4.1451e-02,  2.7143e-03,  6.7224e-02,  1.3388e-02, -4.7576e-03,\n",
      "         2.2472e-02,  3.9915e-02, -3.5502e-02,  8.5582e-02,  4.9538e-02,\n",
      "         3.6261e-02,  1.7423e-02,  2.5702e-02, -8.4623e-02, -7.4408e-03,\n",
      "         4.6536e-03,  5.9347e-02,  5.7252e-02, -1.9220e-03,  1.4606e-02,\n",
      "         1.1267e-01,  4.4309e-02,  7.4564e-02,  9.9461e-03,  6.2325e-02,\n",
      "         8.3018e-02,  8.1336e-02, -8.5727e-03, -2.7874e-02, -2.2640e-02,\n",
      "        -1.3627e-02,  5.9537e-02,  9.4556e-02,  8.0381e-03, -9.2430e-03,\n",
      "         2.2398e-02,  4.0633e-02,  9.3624e-02,  2.8429e-02,  6.4126e-02,\n",
      "         7.4429e-02,  1.1958e-03, -4.3998e-03,  4.2002e-02,  4.7314e-02,\n",
      "         9.3589e-05,  7.9764e-02, -5.0071e-02, -1.9588e-02, -5.5578e-02,\n",
      "         2.9376e-02,  5.8364e-02,  4.4322e-03,  7.9239e-02,  1.3704e-01,\n",
      "         4.5979e-02,  6.8234e-02,  8.7906e-03,  9.1653e-02,  5.3857e-02,\n",
      "         5.5827e-02,  8.3346e-02,  4.9320e-02, -3.3990e-02, -6.7249e-02,\n",
      "         8.8782e-02,  5.6790e-02,  9.1662e-02, -4.1550e-02,  4.8733e-02,\n",
      "         9.2978e-02,  1.6166e-02, -5.4598e-03,  7.8622e-02,  1.0818e-01,\n",
      "        -8.4847e-03,  3.8146e-02, -7.5731e-02, -1.4326e-02,  3.1384e-02,\n",
      "         5.7050e-02, -2.6821e-02, -4.6968e-02, -2.5145e-02,  2.7731e-02,\n",
      "        -2.6006e-03, -6.3323e-03,  3.5228e-02, -2.5015e-02,  3.3593e-02,\n",
      "         1.2307e-02, -3.1149e-02, -5.0997e-02, -5.4269e-02,  4.3543e-02,\n",
      "         3.7695e-02,  3.4092e-02, -9.0835e-02,  4.0645e-02, -6.2330e-02,\n",
      "         3.4371e-02, -3.7499e-02, -9.2772e-02,  5.7544e-02, -6.4624e-02,\n",
      "         9.0748e-03,  2.7020e-02,  1.7317e-02, -2.1357e-02, -7.8041e-02,\n",
      "         2.0886e-02, -1.9425e-02, -6.3762e-02,  9.9920e-03,  5.4850e-03,\n",
      "        -2.9605e-02,  5.1405e-02,  2.9323e-02,  4.4156e-02,  7.1064e-02,\n",
      "         5.8164e-03, -2.3701e-02,  1.1721e-01,  3.9135e-02,  3.8334e-02,\n",
      "        -2.0116e-02,  8.3436e-02,  8.9693e-02, -6.8446e-03, -1.0373e-02,\n",
      "        -1.3214e-02, -1.0457e-02,  1.4345e-01,  9.6658e-02, -1.3436e-03,\n",
      "        -3.0410e-02,  1.0644e-01,  4.2996e-02, -3.7234e-02,  1.3120e-01,\n",
      "         1.5007e-02, -4.0279e-02,  9.0301e-02, -7.9533e-03,  6.5073e-02,\n",
      "         6.7312e-02,  1.2769e-03,  4.1594e-02,  3.7712e-02,  3.8612e-02,\n",
      "        -8.5067e-02,  7.7071e-02, -3.6606e-02,  8.1360e-02, -9.7742e-03,\n",
      "         4.7932e-02,  5.1802e-03, -2.8674e-02,  2.8952e-02,  1.0422e-01,\n",
      "        -4.7396e-02, -5.1197e-02, -3.9611e-02,  1.0614e-01, -2.0505e-02,\n",
      "        -1.6601e-02, -6.7053e-03,  2.8753e-02,  4.2060e-02,  1.3582e-04,\n",
      "        -1.0020e-02,  3.4803e-02,  6.0425e-02,  1.4305e-02, -4.2685e-03,\n",
      "         4.1098e-02,  1.3911e-02, -4.0628e-02,  3.3272e-02, -9.4824e-02,\n",
      "        -1.2106e-02,  3.4015e-02,  3.2900e-02,  3.5670e-02,  3.4872e-02,\n",
      "        -2.0814e-02,  9.9380e-03,  2.3712e-02,  3.4165e-02, -1.7528e-02,\n",
      "         1.0797e-02,  4.3217e-02, -3.2149e-02,  7.2869e-02,  2.5036e-02,\n",
      "         8.7728e-02,  1.0166e-01, -8.8509e-06, -1.5221e-02,  4.6641e-02,\n",
      "         7.6369e-02,  4.8884e-02,  1.9809e-02,  2.7388e-02, -4.1869e-02,\n",
      "         1.1528e-01, -1.0574e-01,  6.7499e-02,  1.0172e-01,  8.1517e-03,\n",
      "        -2.7131e-02,  1.0416e-02, -1.1341e-03, -6.5038e-02,  9.7540e-02,\n",
      "         1.8155e-02,  6.5958e-03, -5.2918e-03, -2.5258e-02,  5.4158e-02,\n",
      "         4.4549e-02, -2.7935e-02,  8.0255e-02,  6.1830e-03, -4.0368e-02,\n",
      "        -1.9171e-02,  5.4374e-02, -1.0476e-02,  4.0898e-02, -1.1445e-02,\n",
      "         3.7550e-02,  1.0269e-02, -4.3974e-02, -2.8261e-02,  4.0613e-02,\n",
      "         3.5255e-02,  3.7857e-02,  9.3451e-02, -2.0009e-02, -5.5193e-03,\n",
      "        -1.9570e-02, -3.2087e-02,  7.6648e-02,  6.7507e-02, -1.0249e-02,\n",
      "         5.4468e-02, -1.9260e-02,  9.3701e-03,  7.7673e-03, -2.8727e-02,\n",
      "         2.0934e-02,  4.8224e-02,  1.0629e-01,  5.2170e-02,  1.5930e-03,\n",
      "         1.4390e-02,  3.8761e-02,  6.8091e-02, -5.9741e-02,  5.9297e-02,\n",
      "         3.4355e-02, -6.3573e-02,  3.3830e-02, -3.1728e-02,  5.1103e-02,\n",
      "        -1.1923e-02, -2.6129e-03, -2.6950e-02, -8.5698e-03,  3.2165e-02,\n",
      "         9.3135e-02,  4.0734e-02,  1.0232e-01,  6.8637e-02,  2.4159e-02,\n",
      "         6.3863e-02,  4.0370e-02,  3.5747e-02, -5.6042e-03, -2.4888e-02,\n",
      "        -2.4388e-02,  1.4280e-02, -1.8268e-02,  7.3193e-02, -3.2889e-03,\n",
      "         7.3769e-02, -9.4803e-03,  4.3435e-02,  5.0578e-02,  6.1190e-02,\n",
      "        -6.7960e-02, -1.9414e-02, -2.6022e-02,  7.1678e-02, -4.4759e-02,\n",
      "         6.6457e-02,  6.6921e-02,  6.5325e-02, -6.7050e-02,  7.4394e-02,\n",
      "        -4.6884e-02, -4.5789e-02,  5.0649e-02,  1.4583e-02,  4.4796e-03,\n",
      "         5.4519e-02,  8.3578e-02,  7.2508e-02,  4.4459e-03,  7.1328e-02,\n",
      "        -4.5553e-02,  4.7231e-02, -2.8324e-02,  6.6894e-02,  2.9447e-02,\n",
      "         8.3070e-02,  1.1164e-01,  1.0949e-01, -2.4256e-02, -5.7531e-02,\n",
      "        -6.1854e-02,  1.0726e-02, -3.1017e-02, -3.3985e-02,  5.0134e-02,\n",
      "        -7.4193e-03,  6.6667e-02,  3.9407e-02,  2.1401e-02,  4.6335e-02,\n",
      "         7.2487e-02,  8.7522e-02, -3.9666e-02,  1.2225e-01,  6.3478e-02,\n",
      "        -5.1460e-02,  1.3618e-01,  6.3801e-02,  7.0489e-03, -8.9234e-03,\n",
      "        -2.0196e-02,  6.7998e-02, -5.9341e-02, -2.5232e-02, -5.2165e-02,\n",
      "        -5.5143e-02,  3.4759e-02, -3.4115e-02,  1.5894e-03,  2.4829e-02,\n",
      "         5.7468e-02,  2.7359e-02,  2.8436e-02, -4.6454e-03,  6.2052e-02,\n",
      "         3.8258e-02, -4.5140e-02,  3.4415e-02, -3.4063e-02,  3.4110e-03,\n",
      "        -1.6631e-02,  1.5636e-02, -4.6818e-03,  1.4086e-01,  8.2858e-03,\n",
      "        -6.8576e-02, -1.5255e-02,  6.5174e-02,  2.9739e-02,  3.0208e-02,\n",
      "        -4.1171e-02,  1.4110e-02,  3.7763e-03,  5.4685e-02,  4.5588e-03,\n",
      "        -5.5301e-02,  1.2789e-02,  1.2241e-02, -1.3911e-02,  1.5516e-02,\n",
      "        -2.5786e-02,  2.4488e-03,  5.7845e-02, -1.1773e-02, -3.6183e-02,\n",
      "         4.2951e-03, -4.5937e-03,  1.0581e-01,  8.0701e-02,  2.9708e-02,\n",
      "         3.4031e-02,  6.1843e-02,  5.9643e-02,  1.7650e-02,  3.2952e-02,\n",
      "        -4.9862e-03,  3.8806e-02,  2.4660e-02, -3.1124e-02,  4.5163e-02,\n",
      "         3.2799e-02, -4.3056e-02, -8.0802e-02,  2.2527e-02,  6.2492e-03],\n",
      "       device='cuda:0')), ('fc2.weight', tensor([[-0.0549, -0.1420,  0.0758,  ...,  0.0495,  0.0680,  0.1024],\n",
      "        [-0.0293,  0.1153, -0.2049,  ..., -0.0657,  0.0213,  0.0675],\n",
      "        [ 0.1346,  0.0723,  0.0161,  ..., -0.0087,  0.0546,  0.0868],\n",
      "        ...,\n",
      "        [-0.1923,  0.1329,  0.0584,  ...,  0.0586, -0.1297, -0.0774],\n",
      "        [-0.1646, -0.2852, -0.0331,  ...,  0.0144,  0.0332,  0.1512],\n",
      "        [ 0.0696, -0.4158,  0.0368,  ...,  0.0465,  0.0206, -0.1684]],\n",
      "       device='cuda:0')), ('fc2.bias', tensor([-0.0478,  0.0021,  0.0072, -0.0144,  0.0308,  0.0160, -0.0151,  0.0012,\n",
      "         0.0370, -0.0134], device='cuda:0'))])\n"
     ]
    }
   ],
   "source": [
    "print(net.state_dict())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5eca385e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_new = Net(input_size, hidden_size, num_classes)\n",
    "device = torch.device(cuda0)\n",
    "model_new.cuda()\n",
    "\n",
    "model_new.load_state_dict(torch.load('model.pth'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "686368bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fc1.weight : True\n",
      "fc1.bias : True\n",
      "fc2.weight : True\n",
      "fc2.bias : True\n"
     ]
    }
   ],
   "source": [
    "for name, param in model_new.named_parameters():\n",
    "    print(name, ':', param.requires_grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "9fb40a89",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(net, 'entire_model.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "10788ea6",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_new1 = torch.load('entire_model.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b2273380",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fc1.weight : False\n",
      "fc1.bias : False\n",
      "fc2.weight : True\n",
      "fc2.bias : True\n"
     ]
    }
   ],
   "source": [
    "for name, param in model_new1.named_parameters():\n",
    "    print(name, ':', param.requires_grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "0042ce2d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Net(\n",
       "  (fc1): Linear(in_features=784, out_features=500, bias=True)\n",
       "  (relu): ReLU()\n",
       "  (fc2): Linear(in_features=500, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(cuda0)\n",
    "model_new1.cuda(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "2190f25e",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()   # Функция потерь\n",
    "optimizer = torch.optim.Adam(model_new1.parameters(), lr=learning_rate)   # Оптимизатор градиентного спуска"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "1f7818b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/5], Step [100/600], Loss: 0.0071\n",
      "Epoch [1/5], Step [200/600], Loss: 0.0144\n",
      "Epoch [1/5], Step [300/600], Loss: 0.0103\n",
      "Epoch [1/5], Step [400/600], Loss: 0.0339\n",
      "Epoch [1/5], Step [500/600], Loss: 0.0061\n",
      "Epoch [1/5], Step [600/600], Loss: 0.0364\n",
      "Epoch [2/5], Step [100/600], Loss: 0.0281\n",
      "Epoch [2/5], Step [200/600], Loss: 0.0195\n",
      "Epoch [2/5], Step [300/600], Loss: 0.0067\n",
      "Epoch [2/5], Step [400/600], Loss: 0.0326\n",
      "Epoch [2/5], Step [500/600], Loss: 0.0293\n",
      "Epoch [2/5], Step [600/600], Loss: 0.0088\n",
      "Epoch [3/5], Step [100/600], Loss: 0.0337\n",
      "Epoch [3/5], Step [200/600], Loss: 0.0051\n",
      "Epoch [3/5], Step [300/600], Loss: 0.0061\n",
      "Epoch [3/5], Step [400/600], Loss: 0.0015\n",
      "Epoch [3/5], Step [500/600], Loss: 0.0032\n",
      "Epoch [3/5], Step [600/600], Loss: 0.0046\n",
      "Epoch [4/5], Step [100/600], Loss: 0.0216\n",
      "Epoch [4/5], Step [200/600], Loss: 0.0007\n",
      "Epoch [4/5], Step [300/600], Loss: 0.0168\n",
      "Epoch [4/5], Step [400/600], Loss: 0.0052\n",
      "Epoch [4/5], Step [500/600], Loss: 0.0101\n",
      "Epoch [4/5], Step [600/600], Loss: 0.0051\n",
      "Epoch [5/5], Step [100/600], Loss: 0.0149\n",
      "Epoch [5/5], Step [200/600], Loss: 0.0027\n",
      "Epoch [5/5], Step [300/600], Loss: 0.0043\n",
      "Epoch [5/5], Step [400/600], Loss: 0.0131\n",
      "Epoch [5/5], Step [500/600], Loss: 0.0023\n",
      "Epoch [5/5], Step [600/600], Loss: 0.0269\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(num_epochs):\n",
    "    for i, (images, labels) in enumerate(train_loader):   # Загрузка партии изображений с индексом, данными, классом\n",
    "             \n",
    "        images = Variable(images.view(-1, 28*28)).to(cuda0)         # Конвертация тензора в переменную: изменяем изображение с вектора, размером 784 на матрицу 28 x 28\n",
    "        labels = Variable(labels).to(cuda0)\n",
    "        \n",
    "        optimizer.zero_grad()                             # Инициализация скрытых масс до нулей\n",
    "        outputs = model_new1(images)     # Передний пропуск: определение выходного класса, данного изображения\n",
    "            \n",
    "        loss = criterion(outputs, labels)                # Определение потерь: разница между выходным классом и предварительно заданной меткой\n",
    "        loss.backward()                                   # Обратный проход: определение параметра weight\n",
    "        optimizer.step()                                  # Оптимизатор: обновление параметров веса в скрытых узлах\n",
    "        \n",
    "        if (i+1) % 100 == 0:                              # Логирование\n",
    "            print('Epoch [%d/%d], Step [%d/%d], Loss: %.4f'\n",
    "                 %(epoch+1, num_epochs, i+1, len(train_dataset)//batch_size, loss.data.item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "0b4c4862",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OrderedDict([('fc1.weight', tensor([[-1.7886e-02,  2.4059e-02,  1.2127e-02,  ...,  8.2212e-03,\n",
      "         -1.6209e-02, -2.3337e-02],\n",
      "        [-3.1160e-02, -2.8851e-02, -2.9725e-02,  ...,  8.0366e-05,\n",
      "          2.5447e-02,  1.7749e-02],\n",
      "        [ 2.4921e-02, -1.5488e-02, -1.4563e-02,  ..., -3.3916e-02,\n",
      "         -3.5218e-02,  4.6975e-03],\n",
      "        ...,\n",
      "        [-6.3645e-04,  1.0396e-02, -1.9093e-02,  ...,  2.0065e-02,\n",
      "          8.5642e-03,  2.7956e-02],\n",
      "        [-3.0655e-02,  2.6850e-02, -2.5427e-02,  ..., -1.5808e-02,\n",
      "          3.0509e-02, -2.7482e-02],\n",
      "        [ 2.1631e-03, -5.4711e-03, -3.0814e-02,  ...,  3.2413e-02,\n",
      "          1.8580e-02, -1.5256e-02]], device='cuda:0')), ('fc1.bias', tensor([ 8.2043e-02,  6.0930e-02,  9.9372e-03, -5.6765e-02,  6.8273e-02,\n",
      "         1.3366e-02, -2.4556e-02,  5.1160e-02, -5.6142e-02, -1.2249e-02,\n",
      "        -5.8979e-03,  8.6617e-02,  1.0421e-01,  3.0909e-02,  4.6933e-02,\n",
      "         8.8124e-02,  7.6432e-02,  7.6576e-02,  6.7188e-02, -2.8336e-02,\n",
      "         3.3370e-02,  4.2127e-02,  1.3977e-02,  6.0468e-02, -2.8506e-02,\n",
      "         1.2651e-02, -2.5851e-02,  2.6722e-03,  2.8102e-02,  4.8534e-02,\n",
      "         4.2012e-02, -1.7587e-02, -6.2868e-02,  6.2016e-03,  2.3811e-02,\n",
      "         3.5235e-03,  2.5781e-02, -4.9496e-02,  8.3044e-02, -5.2250e-02,\n",
      "         6.7084e-02,  5.5141e-02, -3.8233e-03,  5.3941e-03, -8.2093e-02,\n",
      "         9.2013e-03,  6.0008e-02, -2.7361e-02, -1.0967e-02, -4.4540e-02,\n",
      "         1.2168e-02,  7.8466e-02,  2.6082e-02,  9.3506e-02, -1.5546e-02,\n",
      "         4.1067e-02,  8.4301e-02,  2.5206e-02, -1.3205e-02,  8.6457e-02,\n",
      "        -5.1045e-02, -4.5894e-02, -3.3125e-02, -2.1578e-02, -5.8781e-02,\n",
      "         2.1927e-02, -1.4323e-03,  4.9962e-03,  7.3865e-02,  9.4899e-02,\n",
      "         1.6358e-03,  5.6170e-02, -2.8200e-02,  1.5968e-02,  4.4554e-03,\n",
      "         7.4022e-03,  8.8637e-02,  1.2894e-02,  1.5637e-02, -2.1769e-02,\n",
      "         1.2947e-01,  3.7702e-02,  2.0709e-02,  1.3521e-02, -1.6583e-02,\n",
      "         3.3720e-02,  5.8617e-02, -2.2176e-02,  4.1782e-02, -3.5520e-02,\n",
      "         6.2981e-02, -4.1753e-02, -3.7944e-02,  5.1085e-02, -4.1796e-02,\n",
      "        -4.1451e-02,  2.7143e-03,  6.7224e-02,  1.3388e-02, -4.7576e-03,\n",
      "         2.2472e-02,  3.9915e-02, -3.5502e-02,  8.5582e-02,  4.9538e-02,\n",
      "         3.6261e-02,  1.7423e-02,  2.5702e-02, -8.4623e-02, -7.4408e-03,\n",
      "         4.6536e-03,  5.9347e-02,  5.7252e-02, -1.9220e-03,  1.4606e-02,\n",
      "         1.1267e-01,  4.4309e-02,  7.4564e-02,  9.9461e-03,  6.2325e-02,\n",
      "         8.3018e-02,  8.1336e-02, -8.5727e-03, -2.7874e-02, -2.2640e-02,\n",
      "        -1.3627e-02,  5.9537e-02,  9.4556e-02,  8.0381e-03, -9.2430e-03,\n",
      "         2.2398e-02,  4.0633e-02,  9.3624e-02,  2.8429e-02,  6.4126e-02,\n",
      "         7.4429e-02,  1.1958e-03, -4.3998e-03,  4.2002e-02,  4.7314e-02,\n",
      "         9.3589e-05,  7.9764e-02, -5.0071e-02, -1.9588e-02, -5.5578e-02,\n",
      "         2.9376e-02,  5.8364e-02,  4.4322e-03,  7.9239e-02,  1.3704e-01,\n",
      "         4.5979e-02,  6.8234e-02,  8.7906e-03,  9.1653e-02,  5.3857e-02,\n",
      "         5.5827e-02,  8.3346e-02,  4.9320e-02, -3.3990e-02, -6.7249e-02,\n",
      "         8.8782e-02,  5.6790e-02,  9.1662e-02, -4.1550e-02,  4.8733e-02,\n",
      "         9.2978e-02,  1.6166e-02, -5.4598e-03,  7.8622e-02,  1.0818e-01,\n",
      "        -8.4847e-03,  3.8146e-02, -7.5731e-02, -1.4326e-02,  3.1384e-02,\n",
      "         5.7050e-02, -2.6821e-02, -4.6968e-02, -2.5145e-02,  2.7731e-02,\n",
      "        -2.6006e-03, -6.3323e-03,  3.5228e-02, -2.5015e-02,  3.3593e-02,\n",
      "         1.2307e-02, -3.1149e-02, -5.0997e-02, -5.4269e-02,  4.3543e-02,\n",
      "         3.7695e-02,  3.4092e-02, -9.0835e-02,  4.0645e-02, -6.2330e-02,\n",
      "         3.4371e-02, -3.7499e-02, -9.2772e-02,  5.7544e-02, -6.4624e-02,\n",
      "         9.0748e-03,  2.7020e-02,  1.7317e-02, -2.1357e-02, -7.8041e-02,\n",
      "         2.0886e-02, -1.9425e-02, -6.3762e-02,  9.9920e-03,  5.4850e-03,\n",
      "        -2.9605e-02,  5.1405e-02,  2.9323e-02,  4.4156e-02,  7.1064e-02,\n",
      "         5.8164e-03, -2.3701e-02,  1.1721e-01,  3.9135e-02,  3.8334e-02,\n",
      "        -2.0116e-02,  8.3436e-02,  8.9693e-02, -6.8446e-03, -1.0373e-02,\n",
      "        -1.3214e-02, -1.0457e-02,  1.4345e-01,  9.6658e-02, -1.3436e-03,\n",
      "        -3.0410e-02,  1.0644e-01,  4.2996e-02, -3.7234e-02,  1.3120e-01,\n",
      "         1.5007e-02, -4.0279e-02,  9.0301e-02, -7.9533e-03,  6.5073e-02,\n",
      "         6.7312e-02,  1.2769e-03,  4.1594e-02,  3.7712e-02,  3.8612e-02,\n",
      "        -8.5067e-02,  7.7071e-02, -3.6606e-02,  8.1360e-02, -9.7742e-03,\n",
      "         4.7932e-02,  5.1802e-03, -2.8674e-02,  2.8952e-02,  1.0422e-01,\n",
      "        -4.7396e-02, -5.1197e-02, -3.9611e-02,  1.0614e-01, -2.0505e-02,\n",
      "        -1.6601e-02, -6.7053e-03,  2.8753e-02,  4.2060e-02,  1.3582e-04,\n",
      "        -1.0020e-02,  3.4803e-02,  6.0425e-02,  1.4305e-02, -4.2685e-03,\n",
      "         4.1098e-02,  1.3911e-02, -4.0628e-02,  3.3272e-02, -9.4824e-02,\n",
      "        -1.2106e-02,  3.4015e-02,  3.2900e-02,  3.5670e-02,  3.4872e-02,\n",
      "        -2.0814e-02,  9.9380e-03,  2.3712e-02,  3.4165e-02, -1.7528e-02,\n",
      "         1.0797e-02,  4.3217e-02, -3.2149e-02,  7.2869e-02,  2.5036e-02,\n",
      "         8.7728e-02,  1.0166e-01, -8.8509e-06, -1.5221e-02,  4.6641e-02,\n",
      "         7.6369e-02,  4.8884e-02,  1.9809e-02,  2.7388e-02, -4.1869e-02,\n",
      "         1.1528e-01, -1.0574e-01,  6.7499e-02,  1.0172e-01,  8.1517e-03,\n",
      "        -2.7131e-02,  1.0416e-02, -1.1341e-03, -6.5038e-02,  9.7540e-02,\n",
      "         1.8155e-02,  6.5958e-03, -5.2918e-03, -2.5258e-02,  5.4158e-02,\n",
      "         4.4549e-02, -2.7935e-02,  8.0255e-02,  6.1830e-03, -4.0368e-02,\n",
      "        -1.9171e-02,  5.4374e-02, -1.0476e-02,  4.0898e-02, -1.1445e-02,\n",
      "         3.7550e-02,  1.0269e-02, -4.3974e-02, -2.8261e-02,  4.0613e-02,\n",
      "         3.5255e-02,  3.7857e-02,  9.3451e-02, -2.0009e-02, -5.5193e-03,\n",
      "        -1.9570e-02, -3.2087e-02,  7.6648e-02,  6.7507e-02, -1.0249e-02,\n",
      "         5.4468e-02, -1.9260e-02,  9.3701e-03,  7.7673e-03, -2.8727e-02,\n",
      "         2.0934e-02,  4.8224e-02,  1.0629e-01,  5.2170e-02,  1.5930e-03,\n",
      "         1.4390e-02,  3.8761e-02,  6.8091e-02, -5.9741e-02,  5.9297e-02,\n",
      "         3.4355e-02, -6.3573e-02,  3.3830e-02, -3.1728e-02,  5.1103e-02,\n",
      "        -1.1923e-02, -2.6129e-03, -2.6950e-02, -8.5698e-03,  3.2165e-02,\n",
      "         9.3135e-02,  4.0734e-02,  1.0232e-01,  6.8637e-02,  2.4159e-02,\n",
      "         6.3863e-02,  4.0370e-02,  3.5747e-02, -5.6042e-03, -2.4888e-02,\n",
      "        -2.4388e-02,  1.4280e-02, -1.8268e-02,  7.3193e-02, -3.2889e-03,\n",
      "         7.3769e-02, -9.4803e-03,  4.3435e-02,  5.0578e-02,  6.1190e-02,\n",
      "        -6.7960e-02, -1.9414e-02, -2.6022e-02,  7.1678e-02, -4.4759e-02,\n",
      "         6.6457e-02,  6.6921e-02,  6.5325e-02, -6.7050e-02,  7.4394e-02,\n",
      "        -4.6884e-02, -4.5789e-02,  5.0649e-02,  1.4583e-02,  4.4796e-03,\n",
      "         5.4519e-02,  8.3578e-02,  7.2508e-02,  4.4459e-03,  7.1328e-02,\n",
      "        -4.5553e-02,  4.7231e-02, -2.8324e-02,  6.6894e-02,  2.9447e-02,\n",
      "         8.3070e-02,  1.1164e-01,  1.0949e-01, -2.4256e-02, -5.7531e-02,\n",
      "        -6.1854e-02,  1.0726e-02, -3.1017e-02, -3.3985e-02,  5.0134e-02,\n",
      "        -7.4193e-03,  6.6667e-02,  3.9407e-02,  2.1401e-02,  4.6335e-02,\n",
      "         7.2487e-02,  8.7522e-02, -3.9666e-02,  1.2225e-01,  6.3478e-02,\n",
      "        -5.1460e-02,  1.3618e-01,  6.3801e-02,  7.0489e-03, -8.9234e-03,\n",
      "        -2.0196e-02,  6.7998e-02, -5.9341e-02, -2.5232e-02, -5.2165e-02,\n",
      "        -5.5143e-02,  3.4759e-02, -3.4115e-02,  1.5894e-03,  2.4829e-02,\n",
      "         5.7468e-02,  2.7359e-02,  2.8436e-02, -4.6454e-03,  6.2052e-02,\n",
      "         3.8258e-02, -4.5140e-02,  3.4415e-02, -3.4063e-02,  3.4110e-03,\n",
      "        -1.6631e-02,  1.5636e-02, -4.6818e-03,  1.4086e-01,  8.2858e-03,\n",
      "        -6.8576e-02, -1.5255e-02,  6.5174e-02,  2.9739e-02,  3.0208e-02,\n",
      "        -4.1171e-02,  1.4110e-02,  3.7763e-03,  5.4685e-02,  4.5588e-03,\n",
      "        -5.5301e-02,  1.2789e-02,  1.2241e-02, -1.3911e-02,  1.5516e-02,\n",
      "        -2.5786e-02,  2.4488e-03,  5.7845e-02, -1.1773e-02, -3.6183e-02,\n",
      "         4.2951e-03, -4.5937e-03,  1.0581e-01,  8.0701e-02,  2.9708e-02,\n",
      "         3.4031e-02,  6.1843e-02,  5.9643e-02,  1.7650e-02,  3.2952e-02,\n",
      "        -4.9862e-03,  3.8806e-02,  2.4660e-02, -3.1124e-02,  4.5163e-02,\n",
      "         3.2799e-02, -4.3056e-02, -8.0802e-02,  2.2527e-02,  6.2492e-03],\n",
      "       device='cuda:0')), ('fc2.weight', tensor([[-0.0573, -0.1672,  0.0882,  ...,  0.0621,  0.0647,  0.1651],\n",
      "        [-0.0317,  0.1146, -0.3061,  ..., -0.0470,  0.0650,  0.0789],\n",
      "        [ 0.2909,  0.1154, -0.0396,  ..., -0.0272,  0.0985,  0.0964],\n",
      "        ...,\n",
      "        [-0.4141,  0.1559,  0.1358,  ...,  0.0769, -0.1736, -0.0915],\n",
      "        [-0.3614, -0.4132, -0.0518,  ...,  0.0159,  0.0024,  0.1699],\n",
      "        [ 0.1557, -0.5000,  0.0517,  ...,  0.1002,  0.0106, -0.3160]],\n",
      "       device='cuda:0')), ('fc2.bias', tensor([-0.0425, -0.0371, -0.0067, -0.0220,  0.0363,  0.0148, -0.0076, -0.0534,\n",
      "         0.1083, -0.0060], device='cuda:0'))])\n"
     ]
    }
   ],
   "source": [
    "print(model_new1.state_dict())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b30ee1a1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
